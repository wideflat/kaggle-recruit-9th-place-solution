{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kohei\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Kohei\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kohei\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "from collections import defaultdict\n",
    "from sklearn import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = \"C:/Users/Kohei/Documents/Kaggle/Recruit/00_input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(df, cats, inplace_): # inplace=True will delete original feature\n",
    "    for feat in cats:\n",
    "        print('Creating dummy variables for {}'.format(feat))\n",
    "        df_dummy = pd.get_dummies(df[feat], drop_first=True, sparse=True)\n",
    "        df_dummy = df_dummy.rename(columns=lambda x: feat+'_'+ str(x))\n",
    "        df.drop(([feat]), axis=1, inplace=inplace_)\n",
    "        df = pd.merge(df, df_dummy, left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reserve_calc(df):\n",
    "    df['visit_datetime'] = pd.to_datetime(df['visit_datetime'])\n",
    "    df['visit_date'] = df['visit_datetime'].dt.date\n",
    "    df['visit_hour'] = df['visit_datetime'].dt.hour\n",
    "    df['visit_date'] = pd.to_datetime(df['visit_date'])\n",
    "    df['reserve_datetime'] = pd.to_datetime(df['reserve_datetime'])\n",
    "    df['reserve_date'] = df['reserve_datetime'].dt.date\n",
    "    df['reserve_date'] = pd.to_datetime(df['reserve_date'])\n",
    "    df['hr_dif'] = df.apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).seconds/3600, axis=1)\n",
    "    df['hr_dif_24mod'] = df['hr_dif'] % 24\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables for dow\n",
      "Creating dummy variables for month\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>holiday_flg+1d</th>\n",
       "      <th>holiday_flg-1d</th>\n",
       "      <th>holiday_flg_rev</th>\n",
       "      <th>weight</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.605022e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.210044e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.815066e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.042009e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.302511e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.563013e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.823515e-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.084018e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.344520e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.605022e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday_flg visit_date  dow  month  holiday_flg+1d  holiday_flg-1d  \\\n",
       "0            1 2015-12-30    2     12             1.0             0.0   \n",
       "1            1 2015-12-31    3     12             1.0             1.0   \n",
       "2            1 2016-01-01    4      1             1.0             1.0   \n",
       "3            1 2016-01-02    5      1             1.0             1.0   \n",
       "4            1 2016-01-03    6      1             0.0             1.0   \n",
       "5            0 2016-01-04    0      1             0.0             1.0   \n",
       "6            0 2016-01-05    1      1             0.0             0.0   \n",
       "7            0 2016-01-06    2      1             0.0             0.0   \n",
       "8            0 2016-01-07    3      1             0.0             0.0   \n",
       "9            0 2016-01-08    4      1             0.0             0.0   \n",
       "\n",
       "   holiday_flg_rev        weight  dow_1  dow_2    ...     month_3  month_4  \\\n",
       "0                1  2.605022e-14      0      1    ...           0        0   \n",
       "1                1  5.210044e-14      0      0    ...           0        0   \n",
       "2                1  7.815066e-14      0      0    ...           0        0   \n",
       "3                1  1.042009e-13      0      0    ...           0        0   \n",
       "4                1  1.302511e-13      0      0    ...           0        0   \n",
       "5                0  1.563013e-13      0      0    ...           0        0   \n",
       "6                0  1.823515e-13      1      0    ...           0        0   \n",
       "7                0  2.084018e-13      0      1    ...           0        0   \n",
       "8                0  2.344520e-13      0      0    ...           0        0   \n",
       "9                0  2.605022e-13      0      0    ...           0        0   \n",
       "\n",
       "   month_5  month_6  month_7  month_8  month_9  month_10  month_11  month_12  \n",
       "0        0        0        0        0        0         0         0         1  \n",
       "1        0        0        0        0        0         0         0         1  \n",
       "2        0        0        0        0        0         0         0         0  \n",
       "3        0        0        0        0        0         0         0         0  \n",
       "4        0        0        0        0        0         0         0         0  \n",
       "5        0        0        0        0        0         0         0         0  \n",
       "6        0        0        0        0        0         0         0         0  \n",
       "7        0        0        0        0        0         0         0         0  \n",
       "8        0        0        0        0        0         0         0         0  \n",
       "9        0        0        0        0        0         0         0         0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date = pd.read_csv(os.path.join(input_path, 'date_info.csv')).rename(columns={'calendar_date':'visit_date'})\n",
    "\n",
    "# date modification and add next days\n",
    "df_date.drop(['day_of_week'],axis=1, inplace=True)\n",
    "df_date['visit_date'] = pd.to_datetime(df_date['visit_date'])\n",
    "\n",
    "# add next and previous days\n",
    "date1 = [datetime(2017, 6, 1),date(2017, 6, 2)]\n",
    "holiday1 = [0,0]\n",
    "add1 = pd.DataFrame({'visit_date':date1,'holiday_flg':holiday1})\n",
    "\n",
    "date2 = [datetime(2015, 12, 30),date(2015, 12, 31)]\n",
    "holiday2 = [1,1]\n",
    "add2 = pd.DataFrame({'visit_date':date2,'holiday_flg':holiday2})\n",
    "\n",
    "df_date = pd.concat([add2,df_date,add1])\n",
    "df_date['dow'] = df_date['visit_date'].dt.dayofweek\n",
    "df_date['month'] = df_date['visit_date'].dt.month\n",
    "\n",
    "df_date['visit_date+1d'] = (df_date['visit_date'] + timedelta(days=1))\n",
    "\n",
    "\n",
    "# previos 1-6 days\n",
    "for d in range(1,2):\n",
    "    df_date['visit_date-'+str(d)+'d'] = (df_date['visit_date'] - timedelta(days=d*1))\n",
    "\n",
    "\n",
    "# next day's holiday flag\n",
    "tmp = df_date.iloc[:,:2]\n",
    "tmp = tmp.rename(columns={'visit_date':'visit_date+1d','holiday_flg':'holiday_flg+1d'})\n",
    "\n",
    "df_date = pd.merge(df_date, tmp, how='left', on='visit_date+1d')\n",
    "df_date['holiday_flg+1d'] = df_date['holiday_flg+1d'].fillna(0)\n",
    "df_date.drop(['visit_date+1d'],axis=1, inplace=True)\n",
    "\n",
    "# previous day's holiday flag\n",
    "tmp = df_date.iloc[:,:2]\n",
    "tmp = tmp.rename(columns={'visit_date':'visit_date-1d','holiday_flg':'holiday_flg-1d'})\n",
    "\n",
    "df_date = pd.merge(df_date, tmp, how='left', on='visit_date-1d')\n",
    "df_date['holiday_flg-1d'] = df_date['holiday_flg-1d'].fillna(0)\n",
    "df_date.drop(['visit_date-1d'],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# revising holidays\n",
    "# holidays on weekends are not holidays\n",
    "wkend_holidays = df_date.apply((lambda x:(x.dow=='Sunday' or x.dow=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "df_date['holiday_flg_rev'] = df_date['holiday_flg']\n",
    "df_date.loc[wkend_holidays, 'holiday_flg_rev'] = 0\n",
    "\n",
    "# weight\n",
    "df_date['weight'] = (df_date.index + 1) / len(df_date)**5\n",
    "\n",
    "# one-hot-encoding\n",
    "cats = ['dow','month']\n",
    "df_date = dummy(df_date, cats, False)\n",
    "df_date.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors\n",
       "0  air_ba937bf13d40fb24 2016-01-13        25\n",
       "1  air_ba937bf13d40fb24 2016-01-14        32\n",
       "2  air_ba937bf13d40fb24 2016-01-15        29\n",
       "3  air_ba937bf13d40fb24 2016-01-16        22\n",
       "4  air_ba937bf13d40fb24 2016-01-18         6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors = pd.read_csv(os.path.join(input_path, 'air_visit_data.csv'))\n",
    "visitors['visit_date'] = pd.to_datetime(visitors['visit_date'])\n",
    "visitors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### air_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables for air_areaL3_lbl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>var_max_lat</th>\n",
       "      <th>var_max_long</th>\n",
       "      <th>km_latlong</th>\n",
       "      <th>air_areaL1</th>\n",
       "      <th>air_areaL1_lbl</th>\n",
       "      <th>air_areaL2_lbl</th>\n",
       "      <th>...</th>\n",
       "      <th>air_areaL3_lbl_89</th>\n",
       "      <th>air_areaL3_lbl_90</th>\n",
       "      <th>air_areaL3_lbl_91</th>\n",
       "      <th>air_areaL3_lbl_92</th>\n",
       "      <th>air_areaL3_lbl_93</th>\n",
       "      <th>air_areaL3_lbl_94</th>\n",
       "      <th>air_areaL3_lbl_95</th>\n",
       "      <th>air_areaL3_lbl_96</th>\n",
       "      <th>air_areaL3_lbl_97</th>\n",
       "      <th>air_areaL3_lbl_98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>6</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>9.325508</td>\n",
       "      <td>9.075546</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyogo-ken</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>6</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>9.325508</td>\n",
       "      <td>9.075546</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyogo-ken</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>6</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>9.325508</td>\n",
       "      <td>9.075546</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyogo-ken</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>6</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>9.325508</td>\n",
       "      <td>9.075546</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyogo-ken</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>6</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>8.362564</td>\n",
       "      <td>4.521799</td>\n",
       "      <td>1</td>\n",
       "      <td>Tokyo-to</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre   latitude   longitude  var_max_lat  \\\n",
       "0  air_0f0cdeee6c9bf3d7          6  34.695124  135.197852     9.325508   \n",
       "1  air_7cc17a324ae5c7dc          6  34.695124  135.197852     9.325508   \n",
       "2  air_fee8dcf4d619598e          6  34.695124  135.197852     9.325508   \n",
       "3  air_a17f0778617c76e2          6  34.695124  135.197852     9.325508   \n",
       "4  air_83db5aff8f50478e          6  35.658068  139.751599     8.362564   \n",
       "\n",
       "   var_max_long  km_latlong air_areaL1  air_areaL1_lbl  air_areaL2_lbl  \\\n",
       "0      9.075546           0  Hyogo-ken               3              23   \n",
       "1      9.075546           0  Hyogo-ken               3              23   \n",
       "2      9.075546           0  Hyogo-ken               3              23   \n",
       "3      9.075546           0  Hyogo-ken               3              23   \n",
       "4      4.521799           1   Tokyo-to               7              29   \n",
       "\n",
       "         ...          air_areaL3_lbl_89  air_areaL3_lbl_90  air_areaL3_lbl_91  \\\n",
       "0        ...                          0                  0                  0   \n",
       "1        ...                          0                  0                  0   \n",
       "2        ...                          0                  0                  0   \n",
       "3        ...                          0                  0                  0   \n",
       "4        ...                          0                  0                  0   \n",
       "\n",
       "   air_areaL3_lbl_92  air_areaL3_lbl_93  air_areaL3_lbl_94  air_areaL3_lbl_95  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   air_areaL3_lbl_96  air_areaL3_lbl_97  air_areaL3_lbl_98  \n",
       "0                  0                  0                  0  \n",
       "1                  0                  0                  0  \n",
       "2                  0                  0                  0  \n",
       "3                  0                  0                  0  \n",
       "4                  0                  0                  0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_str = pd.read_csv(os.path.join(input_path, 'air_store_info_rev.csv'))\n",
    "\n",
    "air_str['var_max_lat']  = air_str['latitude'].max() - air_str['latitude']\n",
    "air_str['var_max_long'] = air_str['longitude'].max() - air_str['longitude']\n",
    "\n",
    "kmeans = KMeans(n_clusters=12, random_state=0).fit(air_str[['latitude','longitude']])\n",
    "air_str['km_latlong'] = pd.DataFrame(kmeans.predict(air_str[['latitude','longitude']]))\n",
    "\n",
    "\n",
    "air_str.rename(columns={'air_genre_name':'air_genre'}, inplace=True)\n",
    "air_str.rename(columns={'air_area_name':'air_area'}, inplace=True)\n",
    "air_str['air_areaL1'] = air_str['air_area'].apply(lambda x: ' '.join(x.split(' ')[:1]))\n",
    "air_str['air_areaL2'] = air_str['air_area'].apply(lambda x: ' '.join(x.split(' ')[1]))\n",
    "air_str['air_areaL3'] = air_str['air_area'].apply(lambda x: ' '.join(x.split(' ')[2]))\n",
    "\n",
    "air_str['air_genre'] = lbl.fit_transform(air_str['air_genre'])\n",
    "air_str['air_areaL1_lbl'] = lbl.fit_transform(air_str['air_areaL1'])\n",
    "air_str['air_areaL2_lbl'] = lbl.fit_transform(air_str['air_areaL2'])\n",
    "air_str['air_areaL3_lbl'] = lbl.fit_transform(air_str['air_areaL3'])\n",
    "\n",
    "air_str.drop(['air_area','air_areaL2','air_areaL3'],axis=1, inplace=True)\n",
    "\n",
    "cats = ['air_areaL3_lbl']\n",
    "air_str = dummy(air_str, cats, False)\n",
    "air_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hpg_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>hpg_genre</th>\n",
       "      <th>hpg_areaL3</th>\n",
       "      <th>km_hpg_latlong</th>\n",
       "      <th>air_store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_6622b62385aec8bf</td>\n",
       "      <td>15</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_e9e068dd49c5fa00</td>\n",
       "      <td>15</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_2976f7acb4b3a3bc</td>\n",
       "      <td>15</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_e51a522e098f024c</td>\n",
       "      <td>15</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_e3d0e1519894f275</td>\n",
       "      <td>15</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id  hpg_genre                     hpg_areaL3  \\\n",
       "0  hpg_6622b62385aec8bf         15  Tōkyō-to Setagaya-ku Taishidō   \n",
       "1  hpg_e9e068dd49c5fa00         15  Tōkyō-to Setagaya-ku Taishidō   \n",
       "2  hpg_2976f7acb4b3a3bc         15  Tōkyō-to Setagaya-ku Taishidō   \n",
       "3  hpg_e51a522e098f024c         15  Tōkyō-to Setagaya-ku Taishidō   \n",
       "4  hpg_e3d0e1519894f275         15  Tōkyō-to Setagaya-ku Taishidō   \n",
       "\n",
       "   km_hpg_latlong air_store_id  \n",
       "0               7          NaN  \n",
       "1               7          NaN  \n",
       "2               7          NaN  \n",
       "3               7          NaN  \n",
       "4               7          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_str = pd.read_csv(os.path.join(input_path, 'hpg_store_info.csv'))\n",
    "\n",
    "kmeans = KMeans(n_clusters=12, random_state=0).fit(hpg_str[['latitude','longitude']])\n",
    "hpg_str['km_hpg_latlong'] = pd.DataFrame(kmeans.predict(hpg_str[['latitude','longitude']]))\n",
    "\n",
    "hpg_str.rename(columns={'hpg_genre_name':'hpg_genre'}, inplace=True)\n",
    "hpg_str.rename(columns={'hpg_area_name':'hpg_areaL3'}, inplace=True)\n",
    "\n",
    "hpg_str['hpg_genre'] = lbl.fit_transform(hpg_str['hpg_genre'])\n",
    "\n",
    "hpg_str.drop(['latitude','longitude'],axis=1, inplace=True)\n",
    "\n",
    "store = pd.read_csv(os.path.join(input_path, 'store_id_relation.csv'))\n",
    "hpg_str = pd.merge(hpg_str, store, how='left', on=['hpg_store_id'])\n",
    "hpg_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### air_reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visit_hour</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>hr_dif</th>\n",
       "      <th>hr_dif_24mod</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id      visit_datetime    reserve_datetime  \\\n",
       "0  air_877f79706adbfb06 2016-01-01 19:00:00 2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff 2016-01-01 19:00:00 2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff 2016-01-01 19:00:00 2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06 2016-01-01 20:00:00 2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926 2016-01-01 20:00:00 2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors visit_date  visit_hour reserve_date  hr_dif  hr_dif_24mod  \\\n",
       "0                 1 2016-01-01          19   2016-01-01     3.0           3.0   \n",
       "1                 3 2016-01-01          19   2016-01-01     0.0           0.0   \n",
       "2                 6 2016-01-01          19   2016-01-01     0.0           0.0   \n",
       "3                 2 2016-01-01          20   2016-01-01     4.0           4.0   \n",
       "4                 5 2016-01-01          20   2016-01-01    19.0          19.0   \n",
       "\n",
       "   dow  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    4  \n",
       "4    4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_res = pd.read_csv(os.path.join(input_path, 'air_reserve.csv'))\n",
    "air_res = reserve_calc(air_res)\n",
    "air_res['dow'] = air_res['visit_date'].dt.dayofweek\n",
    "\n",
    "air_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hpg_reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visit_hour</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>hr_dif</th>\n",
       "      <th>hr_dif_24mod</th>\n",
       "      <th>dow</th>\n",
       "      <th>air_store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id      visit_datetime    reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f 2016-01-01 11:00:00 2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47 2016-01-01 13:00:00 2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5 2016-01-01 16:00:00 2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a 2016-01-01 17:00:00 2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2 2016-01-01 17:00:00 2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors visit_date  visit_hour reserve_date  hr_dif  hr_dif_24mod  \\\n",
       "0                 1 2016-01-01          11   2016-01-01     2.0           2.0   \n",
       "1                 3 2016-01-01          13   2016-01-01     7.0           7.0   \n",
       "2                 2 2016-01-01          16   2016-01-01     2.0           2.0   \n",
       "3                 5 2016-01-01          17   2016-01-01     6.0           6.0   \n",
       "4                13 2016-01-01          17   2016-01-01    14.0          14.0   \n",
       "\n",
       "   dow air_store_id  \n",
       "0    4          NaN  \n",
       "1    4          NaN  \n",
       "2    4          NaN  \n",
       "3    4          NaN  \n",
       "4    4          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_res = pd.read_csv(os.path.join(input_path, 'hpg_reserve.csv'))\n",
    "hpg_res = reserve_calc(hpg_res)\n",
    "hpg_res['dow'] = hpg_res['visit_date'].dt.dayofweek\n",
    "\n",
    "store = pd.read_csv(os.path.join(input_path, 'store_id_relation.csv'))\n",
    "hpg_res = pd.merge(hpg_res, store, how='left', on=['hpg_store_id'])\n",
    "hpg_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables for weather_daytime\n",
      "Creating dummy variables for weather_nighttime\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefecture</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>wind_max</th>\n",
       "      <th>rainfall_max1h</th>\n",
       "      <th>wind_max_inst</th>\n",
       "      <th>wind_avg</th>\n",
       "      <th>temperature_high</th>\n",
       "      <th>temperature_low</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>daylight_hr</th>\n",
       "      <th>weather_daytime</th>\n",
       "      <th>weather_nighttime</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>weather_daytime_1</th>\n",
       "      <th>weather_daytime_2</th>\n",
       "      <th>weather_daytime_3</th>\n",
       "      <th>weather_nighttime_1</th>\n",
       "      <th>weather_nighttime_2</th>\n",
       "      <th>weather_nighttime_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fukuoka-ken</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fukuoka-ken</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fukuoka-ken</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fukuoka-ken</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukuoka-ken</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prefecture  rainfall  snowfall  wind_max  rainfall_max1h  wind_max_inst  \\\n",
       "0  Fukuoka-ken       0.0         0       4.1             0.0            8.4   \n",
       "1  Fukuoka-ken       0.0         0       5.8             0.0            9.9   \n",
       "2  Fukuoka-ken       1.0         0       3.1             1.0            4.1   \n",
       "3  Fukuoka-ken       0.0         0       4.7             0.0            8.1   \n",
       "4  Fukuoka-ken       1.0         0       7.0             0.5           11.0   \n",
       "\n",
       "   wind_avg  temperature_high  temperature_low  temperature_avg  \\\n",
       "0       2.1              12.6              3.1              7.3   \n",
       "1       2.2              14.7              8.3             11.6   \n",
       "2       1.3              15.2              8.5             11.6   \n",
       "3       1.8              16.5              7.4             11.0   \n",
       "4       1.5              12.4              8.3              9.9   \n",
       "\n",
       "          ...           daylight_hr  weather_daytime  weather_nighttime  \\\n",
       "0         ...                   6.6                3                  0   \n",
       "1         ...                   0.6                0                  0   \n",
       "2         ...                   1.4                0                  3   \n",
       "3         ...                   6.7                3                  0   \n",
       "4         ...                   0.0                0                  0   \n",
       "\n",
       "   visit_date  weather_daytime_1 weather_daytime_2  weather_daytime_3  \\\n",
       "0  2016-01-01                  0                 0                  1   \n",
       "1  2016-01-02                  0                 0                  0   \n",
       "2  2016-01-03                  0                 0                  0   \n",
       "3  2016-01-04                  0                 0                  1   \n",
       "4  2016-01-05                  0                 0                  0   \n",
       "\n",
       "   weather_nighttime_1  weather_nighttime_2  weather_nighttime_3  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "2                    0                    0                    1  \n",
       "3                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jma = pd.read_csv(os.path.join(input_path, 'jma/jma.csv'))\n",
    "jma['visit_date'] = pd.to_datetime(jma['date'])\n",
    "jma.drop('date', axis=1, inplace=True)\n",
    "\n",
    "jma['weather_daytime'] = lbl.fit_transform(jma['weather_daytime'])\n",
    "jma['weather_nighttime'] = lbl.fit_transform(jma['weather_nighttime'])\n",
    "\n",
    "cats = ['weather_daytime','weather_nighttime']\n",
    "jma = dummy(jma, cats, False)\n",
    "jma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(input_path, 'air_visit_data.csv'))\n",
    "train['visit_date'] = pd.to_datetime(train['visit_date'])\n",
    "\n",
    "test = pd.read_csv(os.path.join(input_path, 'sample_submission.csv'))\n",
    "test.drop(['visitors'],axis=1, inplace=True)\n",
    "\n",
    "test['air_store_id'] = test['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "test['visit_date'] = test['id'].apply(lambda x: x.split('_')[-1])\n",
    "test['visit_date'] = pd.to_datetime(test['visit_date'])\n",
    "test.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weighted mean + min,max,count\n",
    "def visit_numeric(df, tmp, prefix, var, alt_var1, alt_var2):\n",
    "    wmean = lambda x:((x.weight * x.y).sum()/x.weight.sum())\n",
    "    df = df.merge(tmp.groupby(var).apply(wmean).reset_index(), on=var, how='left')\n",
    "    df.rename(columns={0:str(prefix)+'_wmean'}, inplace=True)\n",
    "    missing = df[str(prefix)+'_wmean'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_wmean'] = df[missing].merge(tmp.groupby(alt_var1).mean().reset_index(),how='left',on=alt_var1)['y'].values\n",
    "    missing = df[str(prefix)+'_wmean'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_wmean'] = df[missing].merge(tmp.groupby(alt_var2).mean().reset_index(),how='left',on=alt_var2)['y'].values\n",
    "    \n",
    "    # max\n",
    "    df.loc[:,str(prefix)+'_max'] = df.merge(tmp.groupby(var).max().reset_index(), on=var, how='left')['y'].values\n",
    "    missing = df[str(prefix)+'_max'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_max'] = df[missing].merge(tmp.groupby(alt_var1).max().reset_index(),how='left',on=alt_var1)['y'].values\n",
    "    missing = df[str(prefix)+'_max'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_max'] = df[missing].merge(tmp.groupby(alt_var2).max().reset_index(),how='left',on=alt_var2)['y'].values\n",
    "    \n",
    "    # min\n",
    "    df.loc[:,str(prefix)+'_min'] = df.merge(tmp.groupby(var).min().reset_index(), on=var, how='left')['y'].values\n",
    "    missing = df[str(prefix)+'_min'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_min'] = df[missing].merge(tmp.groupby(alt_var1).min().reset_index(),how='left',on=alt_var1)['y'].values\n",
    "    missing = df[str(prefix)+'_min'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_min'] = df[missing].merge(tmp.groupby(alt_var2).min().reset_index(),how='left',on=alt_var2)['y'].values\n",
    "\n",
    "    # med\n",
    "    df.loc[:,str(prefix)+'_med'] = df.merge(tmp.groupby(var).median().reset_index(), on=var, how='left')['y'].values\n",
    "    missing = df[str(prefix)+'_med'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_med'] = df[missing].merge(tmp.groupby(alt_var1).median().reset_index(),how='left',on=alt_var1)['y'].values\n",
    "    missing = df[str(prefix)+'_med'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_med'] = df[missing].merge(tmp.groupby(alt_var2).median().reset_index(),how='left',on=alt_var2)['y'].values\n",
    "\n",
    "    # count\n",
    "    df.loc[:,str(prefix)+'_cnt'] = df.merge(tmp.groupby(var).count().reset_index(), on=var, how='left')['y'].values\n",
    "    missing = df[str(prefix)+'_cnt'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_cnt'] = df[missing].merge(tmp.groupby(alt_var1).count().reset_index(),how='left',on=alt_var1)['y'].values\n",
    "    missing = df[str(prefix)+'_cnt'].isnull()\n",
    "    df.loc[missing,str(prefix)+'_cnt'] = df[missing].merge(tmp.groupby(alt_var2).count().reset_index(),how='left',on=alt_var2)['y'].values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(data_flag, df, begin, end, gap):\n",
    "    \n",
    "    # main data\n",
    "    df_out = df[df.visit_date>=begin]\n",
    "    df_out = df_out[df_out.visit_date<=end]\n",
    "\n",
    "    # data used to create features\n",
    "    df_visitors = visitors[visitors.visit_date<(begin-timedelta(days=gap))]\n",
    "\n",
    "    # prep data to calculate mean\n",
    "    df_tmp = pd.merge(df_visitors, df_date, how='left', on=['visit_date'])\n",
    "    df_tmp = pd.merge(df_tmp, air_str, how='left', on=['air_store_id'])\n",
    "    df_tmp = df_tmp.rename(columns={'visitors':'y'})\n",
    "    df_tmp['y'] = np.log1p(df_tmp['y'])\n",
    "\n",
    "    # prepare main data\n",
    "    df_out = pd.merge(df_out, df_date, how='left', on=['visit_date'])\n",
    "    df_out = pd.merge(df_out, air_str, how='left', on=['air_store_id'])\n",
    "    df_out = pd.merge(df_out, hpg_str[['air_store_id','km_hpg_latlong']], how='left', on=['air_store_id'])\n",
    "\n",
    "    # days from first date\n",
    "    df_out['days_from_first_date'] = df_out.apply(lambda r:(r['visit_date']-pd.to_datetime(begin)+timedelta(days=gap+1)).days, axis=1)\n",
    "    \n",
    "    # flag\n",
    "    if data_flag=='train_all':\n",
    "        df_out['flag'] = 0\n",
    "    elif data_flag=='train1':\n",
    "        df_out['flag'] = 1\n",
    "    elif data_flag=='train2':\n",
    "        df_out['flag'] = 2\n",
    "    elif data_flag=='test':\n",
    "        df_out['flag'] = df_out['days_from_first_date'].apply(lambda x: 1 if x<=6 else 2)\n",
    "    \n",
    "    # store x date\n",
    "    df_out = visit_numeric(df_out, df_tmp, 'dow_all',['air_store_id','dow'],['air_store_id'],['air_store_id'])\n",
    "    df_out = visit_numeric(df_out, df_tmp, 'dowhol_all',['air_store_id','dow','holiday_flg'],['air_store_id','dow'],['air_store_id'])\n",
    "\n",
    "    # target encoding\n",
    "    if data_flag=='test':\n",
    "        tmp = df_tmp.groupby(['air_genre'])['y'].mean().reset_index().rename(columns={'y':'genre_mean'})\n",
    "        df_out  = df_out.merge(tmp, on = ['air_genre'], how='left')\n",
    "        \n",
    "        tmp = df_tmp.groupby(['air_genre','dow'])['y'].mean().reset_index().rename(columns={'y':'genre_dow_mean'})\n",
    "        df_out  = df_out.merge(tmp, on = ['air_genre','dow'], how='left')\n",
    "        \n",
    "        tmp = df_tmp.groupby(['air_areaL3_lbl'])['y'].mean().reset_index().rename(columns={'y':'areaL3_mean'})\n",
    "        df_out  = df_out.merge(tmp, on = ['air_areaL3_lbl'], how='left')\n",
    "        \n",
    "        tmp = df_tmp.groupby(['air_areaL3_lbl','dow'])['y'].mean().reset_index().rename(columns={'y':'areaL3_dow_mean'})\n",
    "        df_out  = df_out.merge(tmp, on = ['air_areaL3_lbl','dow'], how='left')\n",
    "    else:\n",
    "        kf = KFold(df_out.shape[0], n_folds=5, random_state=1234, shuffle=True)\n",
    "        for i, (tr_index,vl_index) in enumerate(kf):\n",
    "            tr, vl = df_out.loc[tr_index].copy(), df_out.loc[vl_index].copy()\n",
    "            tr['y'] = np.log1p(tr['visitors'])\n",
    "            tmp = tr.groupby(['air_genre'])['y'].mean().reset_index().rename(columns={'y':'genre_mean'})\n",
    "            vl  = vl.merge(tmp, on = ['air_genre'], how='left')\n",
    "            \n",
    "            tmp = tr.groupby(['air_genre','dow'])['y'].mean().reset_index().rename(columns={'y':'genre_dow_mean'})\n",
    "            vl  = vl.merge(tmp, on = ['air_genre','dow'], how='left')\n",
    "            \n",
    "            tmp = tr.groupby(['air_areaL3_lbl'])['y'].mean().reset_index().rename(columns={'y':'areaL3_mean'})\n",
    "            vl  = vl.merge(tmp, on = ['air_areaL3_lbl'], how='left')\n",
    "            \n",
    "            tmp = tr.groupby(['air_areaL3_lbl','dow'])['y'].mean().reset_index().rename(columns={'y':'areaL3_dow_mean'})\n",
    "            vl  = vl.merge(tmp, on = ['air_areaL3_lbl','dow'], how='left')\n",
    "            if i==0:\n",
    "                tr_all = vl\n",
    "            else:\n",
    "                tr_all = pd.concat([tr_all,vl])\n",
    "        df_out = tr_all\n",
    "        del tr_all,vl\n",
    "        \n",
    "        \n",
    "    # air_reserve\n",
    "    df_airres = air_res[air_res.reserve_date<(begin-timedelta(days=gap))]\n",
    "    df_out.loc[:,'res_ttl'] = df_out.merge(df_airres.groupby(['air_store_id','visit_date']).sum().reset_index(), on=['air_store_id','visit_date'], how='left')['reserve_visitors'].values\n",
    "    df_out.loc[:,'res_cnt'] = df_out.merge(df_airres.groupby(['air_store_id','visit_date']).count().reset_index(), on=['air_store_id','visit_date'], how='left')['reserve_visitors'].values\n",
    "    df_out.loc[:,'res_mean'] = df_out.merge(df_airres.groupby(['air_store_id','visit_date']).mean().reset_index(), on=['air_store_id','visit_date'], how='left')['reserve_visitors'].values\n",
    "    df_out.loc[:,'res_hr_std'] = df_out.merge(df_airres.groupby(['air_store_id','visit_date']).std().reset_index(), on=['air_store_id','visit_date'], how='left')['visit_hour'].values\n",
    "    \n",
    "    tmp = df_airres.groupby(['air_store_id','visit_date','dow'])['reserve_visitors'].mean().reset_index().rename(columns={'reserve_visitors':'res_ttl'})\n",
    "    tmp = tmp.groupby(['air_store_id','dow'])['res_ttl'].mean().reset_index().rename(columns={'res_ttl':'res_ttl_dow_mean'})\n",
    "    df_out = df_out.merge(tmp, on=['air_store_id','dow'], how='left')\n",
    "    \n",
    "    tmp = df_airres.groupby(['air_store_id','visit_date','dow'])['reserve_visitors'].count().reset_index().rename(columns={'reserve_visitors':'res_cnt'})\n",
    "    tmp = tmp.groupby(['air_store_id','dow'])['res_cnt'].mean().reset_index().rename(columns={'res_cnt':'res_cnt_dow_mean'})\n",
    "    df_out = df_out.merge(tmp, on=['air_store_id','dow'], how='left')\n",
    "\n",
    "    # lagged    \n",
    "    for d in [1,3,5,10,20,30]:\n",
    "        df_out['visit_date-'+str(d)+'d'] = (df_out['visit_date']-timedelta(days=d*1))\n",
    "        df_out.loc[:,'lag_'+str(d)+'d'] = df_out.merge(df_tmp[['air_store_id','visit_date','y']],left_on=['air_store_id','visit_date-'+str(d)+'d'],right_on=['air_store_id','visit_date'], how='left')['y'].values\n",
    "        df_out.drop(['visit_date-'+str(d)+'d'],axis=1, inplace=True)\n",
    "        \n",
    "    for w in range(1,21):\n",
    "        df_out['visit_date-'+str(w)+'w'] = (df_out['visit_date']-timedelta(days=w*7))\n",
    "        df_out.loc[:,'lag_'+str(w)+'w'] = df_out.merge(df_tmp[['air_store_id','visit_date','y']],left_on=['air_store_id','visit_date-'+str(w)+'w'],right_on=['air_store_id','visit_date'], how='left')['y'].values\n",
    "        df_out.loc[:,'lag_res_'+str(w)+'w'] = df_out.merge(df_airres.groupby(['air_store_id','visit_date']).sum().reset_index(),left_on=['air_store_id','visit_date-'+str(w)+'w'],right_on=['air_store_id','visit_date'], how='left')['reserve_visitors'].values\n",
    "        df_out.drop(['visit_date-'+str(w)+'w'],axis=1, inplace=True)\n",
    "    \n",
    "    # moving avg\n",
    "    for d in [5,10,20,30,50,100]:\n",
    "        tmp = df_tmp[df_tmp.visit_date>=(begin-timedelta(days=gap)-timedelta(days=d))]\n",
    "        \n",
    "        tmp2 = tmp.groupby(['air_store_id'])['y'].mean().reset_index().rename(columns={'y':'mean_'+str(d)+'d'})\n",
    "        tmp2['mean_'+str(d)+'d'] = tmp2['mean_'+str(d)+'d'].fillna(0)\n",
    "        df_out = pd.merge(df_out, tmp2, on=['air_store_id'], how='left')\n",
    "        \n",
    "        tmp2 = tmp.groupby(['air_store_id'])['y'].max().reset_index().rename(columns={'y':'max_'+str(d)+'d'})\n",
    "        df_out = pd.merge(df_out, tmp2, on=['air_store_id'], how='left')\n",
    "        \n",
    "        tmp2 = tmp.groupby(['air_store_id'])['y'].min().reset_index().rename(columns={'y':'min_'+str(d)+'d'})\n",
    "        df_out = pd.merge(df_out, tmp2, on=['air_store_id'], how='left')\n",
    "        \n",
    "        tmp2 = tmp.groupby(['air_store_id'])['y'].std().reset_index().rename(columns={'y':'std_'+str(d)+'d'})\n",
    "        df_out = pd.merge(df_out, tmp2, on=['air_store_id'], how='left')\n",
    "        \n",
    "        df_out['scale_to_maxmin_'+str(d)+'d'] =  (df_out['mean_'+str(d)+'d']-df_out['min_'+str(d)+'d'])/(df_out['max_'+str(d)+'d']-df_out['min_'+str(d)+'d'])        \n",
    "        df_out['scale_to_std_'+str(d)+'d'] =  (df_out['mean_'+str(d)+'d'])/(df_out['std_'+str(d)+'d'])        \n",
    "\n",
    "        del tmp, tmp2\n",
    "\n",
    "    for w in [2,4,8]:\n",
    "        tmp = df_tmp[df_tmp.visit_date>=(begin-timedelta(days=gap)-timedelta(days=w*7))]\n",
    "        tmp2 = tmp.groupby(['air_store_id','dow'])['y'].mean().reset_index().rename(columns={'y':'mean_dow_'+str(w)+'w'})\n",
    "        tmp2['mean_dow_'+str(w)+'w'] = tmp2['mean_dow_'+str(w)+'w'].fillna(0)\n",
    "        df_out = pd.merge(df_out, tmp2, on=['air_store_id','dow'], how='left')\n",
    "        \n",
    "        del tmp, tmp2\n",
    "        \n",
    "    # weather\n",
    "    df_out = df_out.merge(jma, left_on=['air_areaL1','visit_date'], right_on=['prefecture','visit_date'], how='left')\n",
    "    df_out.drop(['prefecture','air_areaL1'],axis=1, inplace=True)\n",
    "    df_out.drop(['wind_max_inst','rainfall_max1h','wind_avg','temperature_high','temperature_low','temperature_avg','snowfall_max','humidity_avg','daylight_hr'],axis=1, inplace=True)\n",
    "    \n",
    "    # drop\n",
    "    df_out.drop('weight',axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    # fill na\n",
    "    df_out['na_cnt'] = df_out.isnull().sum(axis=1)\n",
    "    df_out = df_out.fillna(-1)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 9 \n",
      "2 / 9 \n",
      "3 / 9 \n",
      "4 / 9 \n",
      "5 / 9 \n",
      "6 / 9 \n",
      "7 / 9 \n",
      "8 / 9 \n",
      "9 / 9 \n"
     ]
    }
   ],
   "source": [
    "# train_all - 39 days split, 0 days gap\n",
    "ini_date = date(2017,4,23)\n",
    "df_all = pd.DataFrame()\n",
    "split_days = 39\n",
    "skip_days = 39\n",
    "gap_days = 0\n",
    "for i in range(1,int(360/skip_days)+1):\n",
    "    print('%i / %i ' %(i,int(360/skip_days)))\n",
    "    df_out = create_data('train_all', train,\\\n",
    "                         ini_date-timedelta(days=i*skip_days),\\\n",
    "                         ini_date-timedelta(days=i*skip_days)+timedelta(days=(split_days-1)),\\\n",
    "                         gap_days)\n",
    "    df_all = pd.concat([df_all,df_out])\n",
    "df_all.to_csv('train_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 60 \n",
      "2 / 60 \n",
      "3 / 60 \n",
      "4 / 60 \n",
      "5 / 60 \n",
      "6 / 60 \n",
      "7 / 60 \n",
      "8 / 60 \n",
      "9 / 60 \n",
      "10 / 60 \n",
      "11 / 60 \n",
      "12 / 60 \n",
      "13 / 60 \n",
      "14 / 60 \n",
      "15 / 60 \n",
      "16 / 60 \n",
      "17 / 60 \n",
      "18 / 60 \n",
      "19 / 60 \n",
      "20 / 60 \n",
      "21 / 60 \n",
      "22 / 60 \n",
      "23 / 60 \n",
      "24 / 60 \n",
      "25 / 60 \n",
      "26 / 60 \n",
      "27 / 60 \n",
      "28 / 60 \n",
      "29 / 60 \n",
      "30 / 60 \n",
      "31 / 60 \n",
      "32 / 60 \n",
      "33 / 60 \n",
      "34 / 60 \n",
      "35 / 60 \n",
      "36 / 60 \n",
      "37 / 60 \n",
      "38 / 60 \n",
      "39 / 60 \n",
      "40 / 60 \n",
      "41 / 60 \n",
      "42 / 60 \n",
      "43 / 60 \n",
      "44 / 60 \n",
      "45 / 60 \n",
      "46 / 60 \n",
      "47 / 60 \n",
      "48 / 60 \n",
      "49 / 60 \n",
      "50 / 60 \n",
      "51 / 60 \n",
      "52 / 60 \n",
      "53 / 60 \n",
      "54 / 60 \n",
      "55 / 60 \n",
      "56 / 60 \n",
      "57 / 60 \n",
      "58 / 60 \n",
      "59 / 60 \n",
      "60 / 60 \n"
     ]
    }
   ],
   "source": [
    "# train1 - 6 days split, 0 days gap\n",
    "ini_date = date(2017,4,23)\n",
    "df_all = pd.DataFrame()\n",
    "split_days = 6\n",
    "skip_days = 6\n",
    "gap_days = 0\n",
    "for i in range(1,int(360/skip_days)+1):\n",
    "    print('%i / %i ' %(i,int(360/skip_days)))\n",
    "    df_out = create_data('train1', train,\\\n",
    "                         ini_date-timedelta(days=i*skip_days),\\\n",
    "                         ini_date-timedelta(days=i*skip_days)+timedelta(days=(split_days-1)),\\\n",
    "                         gap_days)\n",
    "    df_all = pd.concat([df_all,df_out])\n",
    "df_all.to_csv('train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10 \n",
      "2 / 10 \n",
      "3 / 10 \n",
      "4 / 10 \n",
      "5 / 10 \n",
      "6 / 10 \n",
      "7 / 10 \n",
      "8 / 10 \n",
      "9 / 10 \n",
      "10 / 10 \n"
     ]
    }
   ],
   "source": [
    "# train2 - 33 days split, 6 days gap\n",
    "ini_date = date(2017,4,23)\n",
    "df_all = pd.DataFrame()\n",
    "split_days = 33\n",
    "skip_days = 33\n",
    "gap_days = 6\n",
    "for i in range(1,int(360/split_days)+1):\n",
    "    print('%i / %i ' %(i,int(360/skip_days)))\n",
    "    df_out = create_data('train2', train,\\\n",
    "                         ini_date-timedelta(days=i*skip_days),\\\n",
    "                         ini_date-timedelta(days=i*skip_days)+timedelta(days=(split_days-1)),\\\n",
    "                         gap_days)\n",
    "    df_all = pd.concat([df_all,df_out])\n",
    "df_all.to_csv('train2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all = create_data('test', test, date(2017,4,23), date(2017,5,31), 0)\n",
    "test_all.to_csv('test_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
